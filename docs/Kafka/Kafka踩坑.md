# Kafka踩坑

[toc]

## 保证消息顺序

![image-20221023113743135](/Users/hhh/Library/Application Support/typora-user-images/image-20221023113743135.png)

### 产生原因

网络不稳定或一些其他原因，导致延迟推到broker

### 解决方案

建立单独重试服务机制，消息消费失败，将一整个业务链条消息，放入重试表，统一重试

1.2的kafka消息是无序的，一个topic中包含多个partition，单个partition是有序的，我们只要**保证生产者写消息的时候，按照一定的规则写到同一个partition，不同消费者读不同partition，实现消息有序**，出现网络波动，导致比如下单数据没有成功，但是后续的支付/执行订单消息却发出了，进行了执行，导致数据错乱，后续引入重试机制，每个消息重试3次，还是失败就找开发人员处理，解决该问题的关键是，下单消费不成功，后续的操作也不能成功，就引入XXL-job，专门建立一个重试服务，订单失败，存到重试表中，后续其他的消费上套一个切面，判断是否有同一订单链上的订单执行了后续操作，有的话就也放入重试表，后续继续重试，如果所有重试3次都失败，那么还是需要发邮件给对应的开发人员，介入处理。

![image-20221023113722648](/Users/hhh/Library/Application Support/typora-user-images/image-20221023113722648.png)

## 消息积压

生产者发送过多消息，消费者处理不过来，导致数据看不到。

### 产生原因

- Kafka生产/消费消息，需要经过2次网络io与磁盘io
- 消息体积过大，会导致IO速度延迟，出现消息积压
  - 浪费磁盘，会出现磁盘不足的情况

![image-20221023114859664](/Users/hhh/Library/Application Support/typora-user-images/image-20221023114859664.png)

### 如何优化

发送Kafka消息的时候，只发送最小的消息体，等到消费者接受到消息的时候，回查

![image-20221023115430107](/Users/hhh/Library/Application Support/typora-user-images/image-20221023115430107.png)

## 消息倾斜

我们上面说的，为了保证消费顺序，使用了统一规则，对消息进行partition的区分，这样会出现，如果有的商家订单量过大，会消息倾斜，一个partition数据过大消费者消费不过来，一些partition又没有数据出现空闲。

![image-20221023115700115](/Users/hhh/Library/Application Support/typora-user-images/image-20221023115700115.png)

### 解决方法

不要使用业务规则做我们的路由规则，要使用订单编号这种，系统生成的数据作为消息生产路由规则



## JOB批量发消息导致消息积压

订单促销，使用脚本刷了一大部分数据，导致消息生产者暴增，因为固定了partition的数量与其对应的消费者组，所以加消费者节点无用，只能先改代码，修改为线程池消费数据，但是因为回查，把订单打挂了，只能再调小线程池，慢慢消费

## 表过大-消费者过慢

服务端数据数据表 太大，单表数据太大，导致查询变慢，消费者速度变慢，消息积压

## 主键冲突

根据订单号插入或更新订单，并发较小的时候，没问题，并发量大的时候，会有多个线程同时执行，同时插入的情况，导致主键冲突报错。

### 解决方案

- 加锁，怕redis异常，导致消费延迟，broker数据积压

使用数据库锁，duplicate key update语法，如果有主键冲突，就更新数据

![image-20221023120804319](/Users/hhh/Library/Application Support/typora-user-images/image-20221023120804319.png)



## 数据库主从延迟

主从数据库由于网络原因，偶尔有延迟，导致查询有时候数据返回不完整，加入重试表，如果查询的数据不完整，那么也推入重试表，让其在次消费

## 重复消费

kafka消费支持三种模式

- at most once：最多消费一次 ，消息 可能会丢，但不会重复
- at lease once：最少一次 ，消息处理成功后再进行commit，消息不会丢，但有可能重复
- exactly once：精确传递，将offset作为唯一ID，与消息同时处理，保证处理的原子性，不重复也不丢失

kafka默认的模式为at lease once ，可能会导致重复消费

### 解决方案

- 加锁，或者 duplicate key update

## 多环境消费（数据恢复）

比如多环境共用一个kafka/mysql，prod消息被pre消费了，prod出现消息丢失，那么可以重制Kafka的offset，再推送一次消息



云简项目完成系统联调并提测

| 云简项目完成系统联调并提测      |
| ------------------------------- |
| 2.2.1风险点/敏感词相关提测/上线 |
| 信创测试                        |
| isv-ai/模板相关交接内容         |
| 2.2.2相关内容评审/开发          |













